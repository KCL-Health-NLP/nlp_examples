{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfidf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opW3IYevdSPH",
        "colab_type": "text"
      },
      "source": [
        "# Term frequency x Inverse document frequency - TfIdf\n",
        "\n",
        "With acknowledgement to Mayank Tripathi https://github.com/mayank408\n",
        "\n",
        "We will build on the BoW model creating a TfIdf model from first principles.\n",
        "\n",
        "First a couple imports: \"string\" to do some string manipulation, pprint and pandas to help us print our data structures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO63wordf-EM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import pprint as pp\n",
        "\n",
        "import pandas as pd\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV4f7Rqj5ppo",
        "colab_type": "text"
      },
      "source": [
        "Now our corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrVUGUlSdYXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = ['Klonopin 0.25 mg po every evening, Fluconazole 200 mg po daily, Synthroid 125 mcg po every day',\n",
        "             'she will not consider switching to clozapine',\n",
        "             'lovastatin 40 mg one half tab po daily, multivitamin daily, metformin 500 mg one tab po twice a day',\n",
        "             'Aspirin 81 mg po once daily, Zoloft 25 mg po once daily, Calcium with vitamin D two tablets po once daily']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxiuMhKR55EJ",
        "colab_type": "text"
      },
      "source": [
        "We will \"normalise\" our documents, to lower case them and remove punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLVLgHlCfyFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalised_documents = []\n",
        "for i in documents:\n",
        "    no_punctuation = ''.join(c for c in i if c not in string.punctuation)\n",
        "    normalised_documents.append(no_punctuation.lower())\n",
        "    \n",
        "for i in normalised_documents:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1tQ6ulj6Mhv",
        "colab_type": "text"
      },
      "source": [
        "Let's split in to tokens, to give our \"bags\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT5GUoqdfzW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bows = []\n",
        "for i in normalised_documents:\n",
        "    bows.append(i.split(' '))\n",
        "\n",
        "print(bows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRg3KbQG6Yh3",
        "colab_type": "text"
      },
      "source": [
        "We need to get a set containing all of our unique words, so that we can calculate their relative \n",
        "frequencies in each document and across all documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-xP7G2hgJ7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_set = set()\n",
        "for i in bows:\n",
        "  word_set = word_set.union(set(i))\n",
        "print(word_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-0xW8NyhDpY",
        "colab_type": "text"
      },
      "source": [
        "Let's count how many of each word we have for each of our bags:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ_E4ShfhD-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordCounts = []\n",
        "for i in bows:\n",
        "  thisWordCount = dict.fromkeys(word_set, 0)\n",
        "  for word in i:\n",
        "    thisWordCount[word]+=1\n",
        "  wordCounts.append(thisWordCount)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUUrSFi4iw9F",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at these counts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a_S6GaOjCuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(wordCounts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNNFp1vjQ9P",
        "colab_type": "text"
      },
      "source": [
        "Now we will define ***Term Frequency*** (TF) as the relative frequency of a word in a bag (document) - i.e. what fraction of all words in a document is a particular word? We will define a function to compute this for all of the words in a bag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zV64MVnjRc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeTF(wordCount, bow):\n",
        "    tfDict = {}\n",
        "    bowCount = len(bow)\n",
        "    for word, count in wordCount.items():\n",
        "        tfDict[word] = count/float(bowCount)\n",
        "    return tfDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvu_e1kfjThC",
        "colab_type": "text"
      },
      "source": [
        "We will run this function over all of our bags (documents), and put the resulting TFs in a single data structure. Tale a look and see how documents differ, and how the TFs reflect relative occurence of a word in each document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Ip44KXjT6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "termFreqs = []\n",
        "for i in range(0,len(bows)): \n",
        "  termFreqs.append(computeTF(wordCounts[i],bows[i]))\n",
        "\n",
        "pd.DataFrame(termFreqs) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29ooQaFts7FC",
        "colab_type": "text"
      },
      "source": [
        "Our next function defines ***Inverse Docuemnt Frequency*** - IDF. This measures the rareness of a word across our whole collection of documents. For each word, we divide the total number of documents by the number containing that word. We take the log of this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Htg6sss7Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeIDF(docList):\n",
        "    import math\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "    \n",
        "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "    for doc in docList:\n",
        "        for word, val in doc.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / float(val))\n",
        "        \n",
        "    return idfDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GObZQfcxs9Ip",
        "colab_type": "text"
      },
      "source": [
        "Now we compute IDF for our words. Take a look at the difference between common words like \"mg\" and rare ones like drug names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anbbuwGSs9re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idfs = computeIDF(wordCounts)\n",
        "pp.pprint(idfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx_lMfqg4heF",
        "colab_type": "text"
      },
      "source": [
        "Let's define a function to put TF and IDF together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmQ0Vc_t4iGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeTFIDF(tfBow, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBow.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "    return tfidf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIakOU0o4rJx",
        "colab_type": "text"
      },
      "source": [
        "And now run this over all of the documents in our term frequency list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKwEFIRb4rvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidfs = []\n",
        "for i in termFreqs:\n",
        "  tfidfs.append(computeTFIDF(i, idfs))\n",
        "  \n",
        "\n",
        "  \n",
        "pd.DataFrame(tfidfs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QH3pqWI8IU3",
        "colab_type": "text"
      },
      "source": [
        "How do these compare to the term frequencies? Run the next line to get just the TFs. What differences are there?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_b7x7kv8Iyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(termFreqs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9iSIllZ-wSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}