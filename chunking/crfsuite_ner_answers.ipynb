{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KCL-Health-NLP/nlp_examples/blob/master/chunking/crfsuite_ner_answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kswfly0s7Ltx"
      },
      "source": [
        "# CRF for named entity recognition of clinical concepts\n",
        "\n",
        "In this practical, we will build a named entity recognition classifier using crfsuite, a CRF package integrated with sklearn.\n",
        "\n",
        "Named entity recognition is a structured learning problem, i.e., we want to learn sequence patterns.\n",
        "\n",
        "We will use data from mtsamples again, and build classifiers that find clinical concepts. \n",
        "\n",
        "The 'gold' standard data is *not* manually annotated, it is the output of a clinical concept recognition system developed by Zeljko Kraljevic called 'CAT' (a predecessor to MedCAT), thus this data is not perfect. This system matches concepts to the entire UMLS. We will only use a few example concepts here.\n",
        "\n",
        "Part of this material is adapted, inspired etc from:\n",
        "\n",
        "https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html,\n",
        "\n",
        "Written by Sumithra Velupillai, March 2019, updated February 2021. Updated May 2023 by Angus Roberts acknowledgements and many thanks to Zeljko Kraljevic for the data preparations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r8cmNaCP7Lt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5212634b-41ae-49a6-b0f9-c40b269a6af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_crfsuite\n",
            "  Cloning https://github.com/MeMartijn/updated-sklearn-crfsuite.git to /tmp/pip-install-nudk7254/sklearn-crfsuite_b07df36d560d4adbbfae7e8b7e2df070\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MeMartijn/updated-sklearn-crfsuite.git /tmp/pip-install-nudk7254/sklearn-crfsuite_b07df36d560d4adbbfae7e8b7e2df070\n",
            "  Resolved https://github.com/MeMartijn/updated-sklearn-crfsuite.git to commit 675038761b4405f04691a83339d04903790e2b95\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (0.8.10)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn_crfsuite)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn_crfsuite\n",
            "  Building wheel for sklearn_crfsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn_crfsuite: filename=sklearn_crfsuite-0.3.6-py2.py3-none-any.whl size=10870 sha256=8668843e64315e9f37a8b525fc6718e30e2f18bd5516ed6def4a0b4d107deecb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d3k8yucr/wheels/0b/bc/07/bd75a6f5fa2bf2ea05a5aad8d9ac66d2b5aab93dfd4e1a89de\n",
            "Successfully built sklearn_crfsuite\n",
            "Installing collected packages: python-crfsuite, sklearn_crfsuite\n",
            "Successfully installed python-crfsuite-0.9.9 sklearn_crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "# By default, pip will install the original sklearn_crfsuite package from PyPI\n",
        "# However, this is not compatible with more recent sklearns, and is no longer \n",
        "# being maintained. So we will install from a github fork that is being maintained.\n",
        "# You might be able to go back to the PyPI version in the future, if someone\n",
        "# starts maintiaing it again.\n",
        "try:\n",
        "  import sklearn_crfsuite\n",
        "except ImportError as e:\n",
        "  !pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite\n",
        "  #!pip install sklearn_crfsuite\n",
        "  import sklearn_crfsuite\n",
        "\n",
        "\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "# We use sklearn for scoring, metrics,\n",
        "# and parameter searching\n",
        "import sklearn\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "# We use scipy to make exponential continuous random variables\n",
        "# when parameter searching\n",
        "import scipy\n",
        "\n",
        "# import random\n",
        "\n",
        "# requests is a package to submit requests to URLs\n",
        "# We will use it to fetch our data\n",
        "import requests\n",
        "\n",
        "# We use spacy to create our BILOU tags\n",
        "import spacy\n",
        "from spacy.training import offsets_to_biluo_tags\n",
        "\n",
        "# You might choose to turn off warnings - could be for\n",
        "# documents with no entities, etc\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLnUgt997Lt-"
      },
      "source": [
        "# 4: Training a model with crfsuite\n",
        "There are other machine learning algorithms that can be used for this sequence learning problem. Let's try crfsuite. \n",
        "\n",
        "Let's use some functions to get sentences and tokens in the right format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use a spacy pipeline to POS and BILOU tag our data.\n",
        "# We do not need to have NER, as we will use CRF for that.\n",
        "try:\n",
        "  nlp = spacy.load('en_core_web_sm', exclude=['ner'])\n",
        "except OSError as e:\n",
        "  !python -m spacy download en_core_web_sm\n",
        "  nlp = spacy.load('en_core_web_sm', exclude=['ner'])"
      ],
      "metadata": {
        "id": "_5hFUHfaoB8f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp.pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz6HjFbPoufi",
        "outputId": "e824da86-9c4c-400e-a630-520a0ce0932d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7fd737740760>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x7fd7364283a0>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7fd736f39a80>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7fd7362033c0>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7fd7361d5140>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nInoO4kn7Lt_"
      },
      "outputs": [],
      "source": [
        "# This function loads data from a filename and then\n",
        "# uses SpaCy to get BILUO tags for each sentence.\n",
        "# The parameter bio flags whether these should be\n",
        "# converted to BIO tags\n",
        "def get_sentences(filename, bio=False):\n",
        "    \n",
        "    print('reading data: ', filename)\n",
        "    r = requests.get(filename)\n",
        "    train_data = r.json()\n",
        " \n",
        "    sentences = []\n",
        "        \n",
        "    for text, entities in train_data:\n",
        "        doc = nlp(text)\n",
        "\n",
        "        tags = offsets_to_biluo_tags(doc, entities['entities'])\n",
        "\n",
        "        tag_counter = 0\n",
        "        for sent in doc.sents:\n",
        "            tagged_sentence = []\n",
        "            for tok in sent:\n",
        "                tag = tags[tag_counter]\n",
        "                if bio:\n",
        "                    tag = tag.replace('L-', 'I-')\n",
        "                    tag = tag.replace('U-', 'B-')\n",
        "                w = (tok.text, tok.pos_, tag)\n",
        "                tagged_sentence.append(w)\n",
        "                tag_counter +=1\n",
        "            sentences.append(tagged_sentence)\n",
        "    print('done')\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IsMr1bBY7Lt_"
      },
      "outputs": [],
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nB_QBLf7LuG"
      },
      "source": [
        "Let's use these functions and read in the training and test data. \n",
        "There are different alternative token level representations that can be used.\n",
        "The BIO format (Begin, Inside, Outside) or the BILOU format (Begin, Inside, Last, Outside, Unit).\n",
        "What do you think is better or worse with each of these?\n",
        "In the function below, you can choose either format with the boolean flag 'bio'. Let's start with BIO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cZoX9jD-7LuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30a647e-0964-4af4-ee36-7ba6c218c005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading dat:  https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_traindata_CAT_updated_2021.json?raw=true\n",
            "done\n",
            "reading dat:  https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_testdata_CAT_updated_2021.json?raw=true\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "train_sents = get_sentences('https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_traindata_CAT_updated_2021.json?raw=true', bio=True)\n",
        "test_sents = get_sentences('https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_testdata_CAT_updated_2021.json?raw=true', bio=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_sents[37])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bzbASFppo0f",
        "outputId": "3720590f-9657-463c-ead3-b9fef0899bd0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DET', 'O'), ('catheter', 'NOUN', 'O'), ('was', 'AUX', 'O'), ('then', 'ADV', 'O'), ('removed', 'VERB', 'O'), ('.', 'PUNCT', 'O'), (' ', 'SPACE', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDKEjVZ17LuG"
      },
      "source": [
        "Now let's create the feature and label vectors for the training and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mMbxDNVp7LuG"
      },
      "outputs": [],
      "source": [
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "876SiJa27LuG"
      },
      "source": [
        "What labels do we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "f1B11WtZ7LuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9200630-38a7-42bb-fefa-a990aa61756c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-',\n",
              " 'B-ANATOMY',\n",
              " 'I-ANATOMY',\n",
              " 'I-DISEASESYNDROME',\n",
              " 'B-DISEASESYNDROME',\n",
              " 'B-SIGNSYMPTOM',\n",
              " 'I-SIGNSYMPTOM',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "labels = list(set(x for l in y_test for x in l))\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Ehqw_17LuH"
      },
      "source": [
        "Now let's train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "I7JdLtnN7LuH"
      },
      "outputs": [],
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',             # gradient descent\n",
        "    c1=0.1,                        # L1 regularisation\n",
        "    c2=0.1,                        # L2 regularisation\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True  # Consider transitions not in the training data\n",
        ")\n",
        "crf.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-uAePjJ7LuH"
      },
      "source": [
        "# 5: evaluation\n",
        "How does this model perform on our test data? Let's look at the f1 score first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6Wk5k9uy7LuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26bfe814-386e-48be-d8a6-d2084671e09b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9810388541756578"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl__4Pei7LuH"
      },
      "source": [
        "We can also print a classification report with more details and metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RXtFmUqo7LuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109678ec-198a-4323-caf2-5432b21a90bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "                -       0.00      0.00      0.00         1\n",
            "        B-ANATOMY       0.95      0.84      0.89       945\n",
            "        I-ANATOMY       0.90      0.76      0.82       299\n",
            "I-DISEASESYNDROME       0.81      0.53      0.64       219\n",
            "B-DISEASESYNDROME       0.88      0.71      0.79       480\n",
            "    B-SIGNSYMPTOM       0.93      0.70      0.80       308\n",
            "    I-SIGNSYMPTOM       0.93      0.68      0.79       122\n",
            "                O       0.99      1.00      0.99     36197\n",
            "\n",
            "         accuracy                           0.98     38571\n",
            "        macro avg       0.80      0.65      0.71     38571\n",
            "     weighted avg       0.98      0.98      0.98     38571\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn_crfsuite.utils import flatten\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SL-RZrE7LuI"
      },
      "source": [
        "What do you think? There's a huge imbalance in the number of instances. Do we really want to evaluate the 'O' label? There's also one instance with an erroneous label ('-') Let's look at the results without these labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tVwsR2WR7LuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4700a3-406b-4041-8f8d-dd58754c63d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ANATOMY',\n",
              " 'I-ANATOMY',\n",
              " 'I-DISEASESYNDROME',\n",
              " 'B-DISEASESYNDROME',\n",
              " 'B-SIGNSYMPTOM',\n",
              " 'I-SIGNSYMPTOM']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "labels = list(set(x for l in y_test for x in l if x !='O' and x!='-'))\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Sr9cyDhj7LuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bdd83f8-a078-41ad-f780-35c14b2f8d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "        B-ANATOMY       0.95      0.84      0.89       945\n",
            "        I-ANATOMY       0.90      0.76      0.82       299\n",
            "I-DISEASESYNDROME       0.81      0.53      0.64       219\n",
            "B-DISEASESYNDROME       0.88      0.71      0.79       480\n",
            "    B-SIGNSYMPTOM       0.93      0.70      0.80       308\n",
            "    I-SIGNSYMPTOM       0.93      0.68      0.79       122\n",
            "\n",
            "        micro avg       0.91      0.75      0.82      2373\n",
            "        macro avg       0.90      0.70      0.79      2373\n",
            "     weighted avg       0.91      0.75      0.82      2373\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(metrics.flat_classification_report(y_test, y_pred, labels = labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoZgQRTl7LuI"
      },
      "source": [
        "This was quite different! \n",
        "Try training this model with the BILOU scheme instead. We can do this by converting the BIO tags in the get_sentences function with the boolean flag 'BIO'. Are results better or worse?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1Y-cIfmj7LuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c8553d-d35c-4fe9-d6fb-15922fd9e7cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading dat:  https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_traindata_CAT_updated_2021.json?raw=true\n",
            "done\n",
            "reading dat:  https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_testdata_CAT_updated_2021.json?raw=true\n",
            "done\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "    L-SIGNSYMPTOM       0.92      0.69      0.79        85\n",
            "        L-ANATOMY       0.91      0.77      0.84       222\n",
            "        B-ANATOMY       0.90      0.76      0.82       222\n",
            "        I-ANATOMY       1.00      0.79      0.88        77\n",
            "U-DISEASESYNDROME       0.89      0.75      0.82       316\n",
            "I-DISEASESYNDROME       0.88      0.27      0.42        55\n",
            "B-DISEASESYNDROME       0.83      0.63      0.72       164\n",
            "    U-SIGNSYMPTOM       0.94      0.74      0.83       223\n",
            "L-DISEASESYNDROME       0.83      0.63      0.72       164\n",
            "    B-SIGNSYMPTOM       0.86      0.65      0.74        85\n",
            "    I-SIGNSYMPTOM       0.96      0.68      0.79        37\n",
            "        U-ANATOMY       0.96      0.88      0.92       723\n",
            "\n",
            "        micro avg       0.92      0.76      0.83      2373\n",
            "        macro avg       0.91      0.69      0.77      2373\n",
            "     weighted avg       0.92      0.76      0.83      2373\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_file = 'https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_traindata_CAT_updated_2021.json?raw=true'\n",
        "test_file = 'https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_testdata_CAT_updated_2021.json?raw=true'\n",
        "train_sents = get_sentences(training_file, bio=False)\n",
        "test_sents = get_sentences(test_file, bio=False)\n",
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]\n",
        "\n",
        "new_classes = list(set(x for l in y_test for x in l if x !='O' and x!='-'))\n",
        "\n",
        "c1=0.1\n",
        "c2=0.1\n",
        "\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=c1,\n",
        "    c2=c2,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True,\n",
        ")\n",
        "crf.fit(X_train, y_train)\n",
        "y_pred = crf.predict(X_test)\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_48ygRc_7LuI"
      },
      "source": [
        "# Optional: cross-validation to find best parameters with crfsuite\n",
        "We have used default parameters in the above. We can try to find the best parameters on the training data by cross-validation. \n",
        "\n",
        "__This takes some time, 20 - 30 minutes (even with only 3 folds)!__ \n",
        "\n",
        "You might make it a bit faster by re-reading your data, this time reverting to BIO tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "j5geagZA7LuJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "2666b225-986b-43c8-e5df-4939d8a85b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=CRF(algorithm='lbfgs',\n",
              "                                 all_possible_transitions=True,\n",
              "                                 max_iterations=100),\n",
              "                   n_iter=50, n_jobs=-1,\n",
              "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd737384cd0>,\n",
              "                                        'c2': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd733011c00>},\n",
              "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['L-SIGNSYMPTOM', 'L-ANATOMY', 'B-ANATOMY', 'I-ANATOMY', 'U-DISEASESYNDROME', 'I-DISEASESYNDROME', 'B-DISEASESYNDROME', 'U-SIGNSYMPTOM', 'L-DISEASESYNDROME', 'B-SIGNSYMPTOM', 'I-SIGNSYMPTOM', 'U-ANATOMY']),\n",
              "                   verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=CRF(algorithm=&#x27;lbfgs&#x27;,\n",
              "                                 all_possible_transitions=True,\n",
              "                                 max_iterations=100),\n",
              "                   n_iter=50, n_jobs=-1,\n",
              "                   param_distributions={&#x27;c1&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd737384cd0&gt;,\n",
              "                                        &#x27;c2&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd733011c00&gt;},\n",
              "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=[&#x27;L-SIGNSYMPTOM&#x27;, &#x27;L-ANATOMY&#x27;, &#x27;B-ANATOMY&#x27;, &#x27;I-ANATOMY&#x27;, &#x27;U-DISEASESYNDROME&#x27;, &#x27;I-DISEASESYNDROME&#x27;, &#x27;B-DISEASESYNDROME&#x27;, &#x27;U-SIGNSYMPTOM&#x27;, &#x27;L-DISEASESYNDROME&#x27;, &#x27;B-SIGNSYMPTOM&#x27;, &#x27;I-SIGNSYMPTOM&#x27;, &#x27;U-ANATOMY&#x27;]),\n",
              "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=CRF(algorithm=&#x27;lbfgs&#x27;,\n",
              "                                 all_possible_transitions=True,\n",
              "                                 max_iterations=100),\n",
              "                   n_iter=50, n_jobs=-1,\n",
              "                   param_distributions={&#x27;c1&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd737384cd0&gt;,\n",
              "                                        &#x27;c2&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd733011c00&gt;},\n",
              "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=[&#x27;L-SIGNSYMPTOM&#x27;, &#x27;L-ANATOMY&#x27;, &#x27;B-ANATOMY&#x27;, &#x27;I-ANATOMY&#x27;, &#x27;U-DISEASESYNDROME&#x27;, &#x27;I-DISEASESYNDROME&#x27;, &#x27;B-DISEASESYNDROME&#x27;, &#x27;U-SIGNSYMPTOM&#x27;, &#x27;L-DISEASESYNDROME&#x27;, &#x27;B-SIGNSYMPTOM&#x27;, &#x27;I-SIGNSYMPTOM&#x27;, &#x27;U-ANATOMY&#x27;]),\n",
              "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, max_iterations=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, max_iterations=100)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# from: https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#hyperparameter-optimization\n",
        "\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "# use the same metric for evaluation\n",
        "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
        "                        average='weighted', labels=new_classes)\n",
        "\n",
        "# search\n",
        "rs = RandomizedSearchCV(crf, params_space,\n",
        "                        cv=3,\n",
        "                        verbose=1,\n",
        "                        n_jobs=-1,\n",
        "                        n_iter=50,\n",
        "                        scoring=f1_scorer)\n",
        "rs.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hKjwDiLQ7LuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d11014-06c5-47d0-9322-6658758b581e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best params: {'c1': 0.1727635814257965, 'c2': 0.005001234271500444}\n",
            "best CV score: 0.8311706051427139\n"
          ]
        }
      ],
      "source": [
        "print('best params:', rs.best_params_)\n",
        "print('best CV score:', rs.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ceiqIXwo7LuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8da8c1-a47e-4f57-bf09-294ef050fae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "    L-SIGNSYMPTOM      0.952     0.706     0.811        85\n",
            "        L-ANATOMY      0.921     0.793     0.852       222\n",
            "        B-ANATOMY      0.911     0.784     0.843       222\n",
            "        I-ANATOMY      0.984     0.818     0.894        77\n",
            "U-DISEASESYNDROME      0.895     0.832     0.862       316\n",
            "I-DISEASESYNDROME      0.882     0.273     0.417        55\n",
            "B-DISEASESYNDROME      0.847     0.640     0.729       164\n",
            "    U-SIGNSYMPTOM      0.933     0.816     0.871       223\n",
            "L-DISEASESYNDROME      0.847     0.640     0.729       164\n",
            "    B-SIGNSYMPTOM      0.887     0.647     0.748        85\n",
            "    I-SIGNSYMPTOM      1.000     0.649     0.787        37\n",
            "        U-ANATOMY      0.962     0.907     0.934       723\n",
            "\n",
            "        micro avg      0.925     0.791     0.853      2373\n",
            "        macro avg      0.918     0.709     0.790      2373\n",
            "     weighted avg      0.922     0.791     0.847      2373\n",
            "\n"
          ]
        }
      ],
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(X_test)\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=new_classes, digits=3\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NA0GECi7LuJ"
      },
      "source": [
        "What do you think? Are there other parameters that could be tested in the cross-validation setup? What about the measure used for optimisation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMjrSAZD7LuJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}