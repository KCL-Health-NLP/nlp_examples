{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMf5rQNOt0WjZACF5WaEUTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KCL-Health-NLP/nlp_examples/blob/master/ann/fine_tune_transformer_with_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tune spaCy's default transformer for medical NER\n",
        "\n",
        "This uses the same data as in the spaCy NER notebook, and follows much the same pattern as that. See that notebook for more detail.\n",
        "\n",
        "It is very version dependent and fragile.\n",
        "\n",
        "It is time consuming:\n",
        "* using cuda\n",
        "* 122 documents in training set\n",
        "* aborted after:\n",
        "  * 1 hour 35 mins\n",
        "  * 171 epochs\n",
        "  * 8400 instances\n",
        "  * P 0.80, R 0.66\n",
        "\n",
        "See the [spaCy Embeddings and Transformers guide](https://spacy.io/usage/embeddings-transformers) for up to date information on installation with CUDA.\n",
        "\n",
        "See the [spaCy installation guide](https://spacy.io/usage#installation) for information on installing spaCy for GPU use.\n",
        "\n",
        "See [this discussion](https://github.com/explosion/spaCy/discussions/12353) on versions of CUDA and PyTorch to use, as of March 2023. At that point, the recommendation was to use CUDA 11.8. Couldn't get this to work, so used the below with 11.3\n",
        "\n"
      ],
      "metadata": {
        "id": "HFm2K-hNSQOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Make sure your runtime is using a GPU***"
      ],
      "metadata": {
        "id": "96LS9dsmMjY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install cuda\n",
        "!sed -i '/developer\\.download\\.nvidia\\.com\\/compute\\/cuda\\/repos/d' /etc/apt/sources.list.d/*\n",
        "!sed -i '/developer\\.download\\.nvidia\\.com\\/compute\\/machine-learning\\/repos/d' /etc/apt/sources.list.d/*\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb\n",
        "!dpkg -i cuda-keyring_1.0-1_all.deb\n",
        "!apt-get update\n",
        "!apt-get -y install cuda-11.3"
      ],
      "metadata": {
        "id": "wbpldihfkjG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Now need to restart runtime***"
      ],
      "metadata": {
        "id": "S2wjiQBao6Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# export cuda path\n",
        "!export CUDA_PATH=\"/usr/local/cuda-11.3\""
      ],
      "metadata": {
        "id": "l3VLJZewnwEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install torch\n",
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ],
      "metadata": {
        "id": "RshrcEW2w5Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install spaCy with the extras for our\n",
        "# CUDA version and transformers\n",
        "!pip install -U spacy[cuda-113,transformers]"
      ],
      "metadata": {
        "id": "fk_UJcQJikwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data for training\n",
        "import requests\n",
        "data_url = 'https://github.com/KCL-Health-NLP/nlp_examples/blob/master/chunking/chunking_traindata_CAT_updated_2021.json?raw=true'\n",
        "r = requests.get(data_url)\n",
        "data = r.json()"
      ],
      "metadata": {
        "id": "99AZoU5pskb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How much training data is there?\n",
        "print(len(train_data))"
      ],
      "metadata": {
        "id": "UTZfJ73-KaTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we use sklearn to split our training data in to train\n",
        "# and dev portions (we have a separate, held out\n",
        "# final test set)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, dev_data = train_test_split(data, train_size=0.8) "
      ],
      "metadata": {
        "id": "3X4f1h2Ny0Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spacy for creating docbins\n",
        "import spacy\n",
        "nlp = spacy.blank('en')\n",
        "\n",
        "# DocBin is a serialisable collection of spacy\n",
        "# Documents.\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# We will generate warnings for some thing\n",
        "# You might uncomment to ignore them\n",
        "import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "V3OZbfDVs6mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A DocBin is a serialisable SpaCy container that holds\n",
        "# SpaCy documents, and which can be used in SpaCy training.\n",
        "# This function converts our data format in to a DocBin\n",
        "def data_to_docbin(json_corpus):\n",
        "  \n",
        "  # We create a DocBin to hold out Documents\n",
        "  db = DocBin()\n",
        "  \n",
        "  # The json_corpus contains text and annotations\n",
        "  for text, annot in json_corpus:\n",
        "\n",
        "    # create Document object from text\n",
        "    # this will conatin the tokens and\n",
        "    # their spans\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Now let's get the entities in to a list \n",
        "    ents = []\n",
        "\n",
        "    # The annotations from our data have a start offset,\n",
        "    # an end offset and a label\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "\n",
        "      # Make a span in our document for these\n",
        "      span = doc.char_span(start, end, label=label)\n",
        "\n",
        "      # If the Document can't align the character offsets with tokens,\n",
        "      # it will return None. We will ignore any entities like this,\n",
        "      # as they could break our training\n",
        "      if span is None:\n",
        "        warnings.warn(f'Skipping entity [{start}, {end}, {label}] : span does not align with token boundaries')\n",
        "      else:\n",
        "        ents.append(span)\n",
        "\n",
        "    # Add the entities to the document\n",
        "    # and add the document to the DocBin\n",
        "    doc.set_ents(ents)\n",
        "    db.add(doc)\n",
        "\n",
        "  # return the DocBin containing all the Documents\n",
        "  # with their text and entities\n",
        "  return db"
      ],
      "metadata": {
        "id": "Pw1WGEWRtUz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data and save to disk\n",
        "\n",
        "train_doc_bin = data_to_docbin(train_data)\n",
        "data_doc_bin.to_disk(\"./train.spacy\") \n",
        "\n",
        "dev_doc_bin = data_to_docbin(dev_data)\n",
        "dev_doc_bin.to_disk(\"./dev.spacy\") \n"
      ],
      "metadata": {
        "id": "Ou5r0jIgtbKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a locale error on spacy init - this is a quick fix\n",
        "# Code from https://github.com/explosion/spaCy/issues/11909\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "9pUFhAc0vStf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Now get your spaCy base config file, for transformers and ner***"
      ],
      "metadata": {
        "id": "mxUsW1B-NGY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise spacy config file\n",
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "vf0qetF7uWNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if using torch\n",
        "import torch\n",
        "print('Torch available:', torch.cuda.is_available())\n",
        "print('Number of torch devices:', torch.cuda.device_count())\n",
        "print('Torch current device:', torch.cuda.current_device())"
      ],
      "metadata": {
        "id": "xodbKQ1sJuMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The flag -g 0 will target at gpu number 0 (i.e. the first gpu)\n",
        "!python -m spacy train -g 0 config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy"
      ],
      "metadata": {
        "id": "0dBAFkCFwmUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}