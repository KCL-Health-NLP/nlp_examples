{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "*(Credit: Leon Derczynski, IT University of Copenhagen)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some embeddings, and then use these to see which words are close to each other.\n",
    "We'll use the gensim package's word2vec implementation, and an nltk corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import brown, movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate word vectors over the Brown corpus text. We will have 20 dimensions, using a window of five for the context words in the skip-grams (e.g. c1, c2, w, c3, c4). This might be a little slow (maybe 1-2 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the Brown corpus\n",
    "b = Word2Vec(brown.sents(), size=100, window=3, min_count=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the vectors, we can see how good they are by measuring which words are similar to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crowd', 0.9577046632766724),\n",
       " ('cabin', 0.9551997780799866),\n",
       " ('wheel', 0.9507994055747986),\n",
       " ('vision', 0.9496356844902039),\n",
       " ('enemy', 0.9474828243255615)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.most_similar('company', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great, eh? Try altering the window and the dimension size, to see if you get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try also with the movie reviews results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the movie review corpus\n",
    "mr = Word2Vec(movie_reviews.sents(), size=20, window=5, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('constantly', 0.7110123634338379),\n",
       " ('killing', 0.6960628032684326),\n",
       " ('talking', 0.6886349320411682),\n",
       " ('lastly', 0.6733138561248779),\n",
       " ('suspect', 0.6698964834213257)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.most_similar('love', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do some arithmetic with the words. Let's try that classical result, king - man + woman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"other's\", 0.9216543436050415),\n",
       " ('chromatographic', 0.9152492880821228),\n",
       " ('lower', 0.9129438996315002),\n",
       " ('tax', 0.9011315703392029),\n",
       " ('religious', 0.9001179337501526)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.most_similar(positive=['biggest', 'small'], negative=['big'], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a perfect result with the default model! Why don't we try loading a bigger dataset, based on a bigger vocabulary. This should give better results. You'll need the GloVe embeddings for this. Download from the the Moodle, or www.derczynski.com/glove.twitter.27B.25d.txt.bz2 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load these in using Gensim; they might take a minute to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove = KeyedVectors.load_word2vec_format(\"./glove.twitter.27B.25d.txt.bz2\", binary=False)\n",
    "print(\"Done loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try the above again. Can you find any cool word combinations? What differences are there in the datasets?\n",
    "\n",
    "Here are some ideas to try, substitute your own words in to these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bread', 0.9616428017616272),\n",
       " ('corn', 0.9524654150009155),\n",
       " ('egg', 0.9472206234931946),\n",
       " ('fish', 0.9398375153541565),\n",
       " ('soup', 0.927527666091919)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar('meat', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average', 0.8820493221282959),\n",
       " ('human', 0.8792450428009033),\n",
       " ('persons', 0.8779707551002502),\n",
       " ('smallest', 0.8638321161270142),\n",
       " ('potential', 0.8624012470245361)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(positive=['biggest', 'small'], negative=['big'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('meets', 0.8841923475265503),\n",
       " ('prince', 0.832163393497467),\n",
       " ('queen', 0.8257461786270142),\n",
       " ('â€™s', 0.8174098134040833),\n",
       " ('crow', 0.8134994506835938),\n",
       " ('hunter', 0.8131037950515747),\n",
       " ('father', 0.8115834593772888),\n",
       " ('soldier', 0.81113600730896),\n",
       " ('mercy', 0.8082392811775208),\n",
       " ('hero', 0.8082263469696045)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77646496599304926"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.similarity('car', 'bike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64489537486365123"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.similarity('car', 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86647633586901729"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.similarity('red', 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.doesnt_match(\"red green horse blue\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
