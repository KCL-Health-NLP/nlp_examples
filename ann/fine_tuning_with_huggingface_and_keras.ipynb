{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPiJPsQHT5vG0cANAHfySsK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KCL-Health-NLP/nlp_examples/blob/master/fine_tuning_with_huggingface_and_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning a Hugging Face model with Keras\n",
        "Based on this [Hugging Face tutorial](https://huggingface.co/docs/transformers/training)"
      ],
      "metadata": {
        "id": "6P_cFMtRUY-8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BN1esalPBbz"
      },
      "outputs": [],
      "source": [
        "# Hugging Face transformers and datasets installation\n",
        "!pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Restart***"
      ],
      "metadata": {
        "id": "Nx7pVsFp_tRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import evaluate\n",
        "\n",
        "# For displaying models\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import model_to_dot\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import SVG"
      ],
      "metadata": {
        "id": "AXvP3IQbTGnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMDB"
      ],
      "metadata": {
        "id": "h95FmlnYOIdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data"
      ],
      "metadata": {
        "id": "JC3hBD3XQsSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_imdb = load_dataset(\"imdb\")\n",
        "ds_imdb"
      ],
      "metadata": {
        "id": "UtcvpJm9OH3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduce size of dataset to speed up"
      ],
      "metadata": {
        "id": "LFYMOg3LQ5uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train_sm = ds_imdb['train'].shuffle(seed=42).select(range(600))\n",
        "ds_train_sm = ds_train_sm.train_test_split(test_size=0.2)\n",
        "ds_train_sm"
      ],
      "metadata": {
        "id": "iAfPJwhSOSUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenise"
      ],
      "metadata": {
        "id": "gMSS8zWQQufh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "def tokenize(batch):\n",
        "    text = tokenizer(batch['text'], return_tensors='np', padding=True, truncation=True, max_length=128)\n",
        "    return (dict(text), np.array(batch['label']))"
      ],
      "metadata": {
        "id": "P3EMlMwoOoRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = tokenize(ds_train_sm['train'])\n",
        "val_x, val_y =  tokenize(ds_train_sm['test'])\n",
        "print(train_y)\n",
        "print('\\n'*4)\n",
        "print(train_x)"
      ],
      "metadata": {
        "id": "OVgb7d5UOth5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model"
      ],
      "metadata": {
        "id": "D92yMvimV3Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and compile our model\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# Lower learning rates are often better for fine-tuning transformers\n",
        "#model.compile(loss=\"binary_crossentropy\", optimizer=Adam(3e-5), metrics=[\"accuracy\"])\n",
        "model.compile(optimizer=Adam(3e-5), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "_EefeoFMQhwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=10)"
      ],
      "metadata": {
        "id": "atw59lSGQst-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MXq0Z903RQrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_test_sm = ds_imdb['test'].shuffle(seed=42).select(range(500))\n",
        "ds_test_sm"
      ],
      "metadata": {
        "id": "cfGwOeYlRcyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x, test_y = tokenize(ds_test_sm)"
      ],
      "metadata": {
        "id": "EfTVTlcBRtLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_x, test_y)\n",
        "print(f\"{'Test loss:':16}{score[0]:.2f}\")\n",
        "print(f\"{'Test accuracy:':16}{score[1]:.2f}\")"
      ],
      "metadata": {
        "id": "bhgL4wlASDjc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}