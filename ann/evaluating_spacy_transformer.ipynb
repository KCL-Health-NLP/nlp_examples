{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLVWiB01QIeNcg119xVJxg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KCL-Health-NLP/nlp_examples/blob/master/ann/evaluating_spacy_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data:\n",
        "https://www.clips.uantwerpen.be/conll2003/ner/\n",
        "\n"
      ],
      "metadata": {
        "id": "OAg8btemBiG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Make sure to change your runtime type to GPU***"
      ],
      "metadata": {
        "id": "iyW1sEQlrKP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://spacy.io/usage\n",
        "# seems ok to ignore the errors?\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U 'spacy[transformers,cuda-autodetect]'"
      ],
      "metadata": {
        "id": "BEthIoJNtQdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***You must retart your runtime now***"
      ],
      "metadata": {
        "id": "GstuuWxLJkqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are using spaCy for NER.\n",
        "import spacy\n",
        "\n",
        "# DocBin is a serialisable collection of spacy\n",
        "# Documents.\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Displacy provides a graphic display of\n",
        "# documents and annotations, and Scorer scores...\n",
        "from spacy import displacy\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "# Example holds spacy documents,\n",
        "# one with predicted annotations\n",
        "# and one with gold standard .\n",
        "# We will use it when evalusating.\n",
        "from spacy.training import Example\n"
      ],
      "metadata": {
        "id": "ZqUzRghzoi18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check we are using torch.cuda\n",
        "import torch\n",
        "print('Torch available:', torch.cuda.is_available())\n",
        "print('Number of torch devices:', torch.cuda.device_count())\n",
        "print('Torch current device:', torch.cuda.current_device())"
      ],
      "metadata": {
        "id": "dM0C7p1vyd87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a locale error on spacy init with GPU - here's a quick fix\n",
        "# Code from https://github.com/explosion/spaCy/issues/11909\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "gsobF2vrsGJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download spacy models\n",
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "z1X_QC0Kq1jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data\n",
        "!wget https://github.com/KCL-Health-NLP/nlp_examples/raw/master/ann/conll2003_test.txt"
      ],
      "metadata": {
        "id": "FQXgoHE6E9kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at our test data\n",
        "!head -100 ./conll2003_test.txt"
      ],
      "metadata": {
        "id": "q8nMLst3oxD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CoNLL LOC == spaCy GPE + spaCy LOC\n",
        "* CoNLL PER == spaCy PERSON\n",
        "* CoNLL ORG == spaCy ORG"
      ],
      "metadata": {
        "id": "MXp_OedGBuOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/-LOC/-GPE/g' conll2003_test.txt\n",
        "!sed -i 's/-PER/-PERSON/g' conll2003_test.txt"
      ],
      "metadata": {
        "id": "KLAbs_XeEthj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take another look at our test data\n",
        "!head -100 ./conll2003_test.txt"
      ],
      "metadata": {
        "id": "zHpSOUUZNebu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to .spacy DocBin format\n",
        "!python -m spacy convert ./conll2003_test.txt . -c ner -n 10\n"
      ],
      "metadata": {
        "id": "V2UFRx3WU3kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB if you did not restart your runtime after installing spaCy (first code cell), then downloading the trf model will fail."
      ],
      "metadata": {
        "id": "OnmPqO_sJwOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spacy models\n",
        "nlp_lg = spacy.load('en_core_web_lg')\n",
        "nlp_tr = spacy.load('en_core_web_trf')"
      ],
      "metadata": {
        "id": "Xmjfj85ApUbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = DocBin().from_disk(\"./conll2003_test.spacy\")"
      ],
      "metadata": {
        "id": "G8Pl04KowwxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(docs))"
      ],
      "metadata": {
        "id": "GFL_j9EVw7-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in docs.get_docs(nlp_lg.vocab):\n",
        "  print(doc.ents)\n"
      ],
      "metadata": {
        "id": "zHPyk7Qz-8Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_nlp(docs, pipeline):\n",
        "  scorer = Scorer()\n",
        "  examples = []\n",
        "  for gold_doc in docs.get_docs(pipeline.vocab):\n",
        "    pred_doc = pipeline(gold_doc.text)\n",
        "    ex = Example(pred_doc, gold_doc)\n",
        "    examples.append(ex)\n",
        "  return (scorer.score(examples), examples)"
      ],
      "metadata": {
        "id": "2Rd6bEngNu8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Add crude timing in to this next cell***"
      ],
      "metadata": {
        "id": "G256t8TJKFl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scores_lg, examples_lg = score_nlp(docs, nlp_lg)\n",
        "scores_tr, examples_tr = score_nlp(docs, nlp_tr)\n",
        "\n"
      ],
      "metadata": {
        "id": "7OdbhUjrzZUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['GPE', 'ORG', 'PERSON']\n",
        "metrics = ['p', 'r', 'f']\n",
        "print(f'{\"label\": <18}{\"score\": <8}{\"lg\": <6}{\"tr\": <6}')\n",
        "for l in labels:\n",
        "  for m in metrics:\n",
        "    lg = scores_lg['ents_per_type'][l][m]\n",
        "    tr = scores_tr['ents_per_type'][l][m]\n",
        "    print(f'{l: <18}{m: <8}{lg: <6.2f}{tr: <6.2f}')"
      ],
      "metadata": {
        "id": "DMn4iEZmHKyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display documents\n",
        "\n",
        "doc_num = 150\n",
        "\n",
        "doc_tr = examples_tr[doc_num].predicted\n",
        "doc_tr.user_data[\"title\"] = \"Transformer model predictions\"\n",
        "\n",
        "doc_lg = examples_lg[doc_num].predicted\n",
        "doc_lg.user_data[\"title\"] = \"Large model predictions\"\n",
        "\n",
        "doc_ref = examples_tr[doc_num].reference\n",
        "doc_ref.user_data[\"title\"] = \"Reference standard\"\n",
        "\n",
        "# Display in displacy\n",
        "displacy.render(doc_tr, style='ent', jupyter=True, options={'ents':labels})\n",
        "print('\\n'*2)\n",
        "displacy.render(doc_lg, style='ent', jupyter=True, options={'ents':labels})\n",
        "print('\\n'*2)\n",
        "displacy.render(doc_ref, style='ent', jupyter=True, options={'ents':labels})"
      ],
      "metadata": {
        "id": "GhqSJWJzJ3hc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}