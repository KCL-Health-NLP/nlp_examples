{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started with Hugging Face endpoint model endpoints\n",
        "\n",
        "---\n",
        "\n",
        "* This notebook is to test that you can connect to a LLM hosted at a Hugging Face endpoint, before doing the other LLM practicals.\n",
        "\n",
        "* You will need to create a Hugging Face account and get an API token from that account. Details of how to do this are given below.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1itC_4Z1tdtg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For documentation see https://python.langchain.com/docs/integrations/llms/huggingface_pipelines\n"
      ],
      "metadata": {
        "id": "LyQ3t2iXVou7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "deb93edpyQjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will be using LangChain\n",
        "!pip install --quiet langchain langchain_community\n",
        "import langchain_community\n",
        "from langchain_community.llms import HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "I_UanP0nUdV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Hugging Face account and API token\n",
        "\n",
        "We will be using a LLM hosted on a Hugging Face endpoint. In order to use this, you will need a Hugging Face account and API token.\n",
        "\n",
        "#### Hugging Face account\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Open https://huggingface.co/\n",
        "1.   Click the \"Sign Up\" button at top right\n",
        "1.   Fill in your email address and a new password and click \"Next\"\n",
        "1.   Enter details on your user profile page. You will need to enter a username and full name, the rest is optional\n",
        "1.   Select the terms and conditions check box\n",
        "1.   Click \"Create Account\"\n",
        "1.   You will be sent a verificaiton email with a link to click, completing account creation\n",
        "\n",
        "#### Hugging Face API token\n",
        "\n",
        "1. Log in to Hugging Face https://huggingface.co/\n",
        "1. Click your account icon at top right\n",
        "1. Select the \"Settings\" option towards the bottom of the menu\n",
        "1. From the Settings menu on the left of the window, select \"Access Tokens\"\n",
        "1. Click the \"New token\" button\n",
        "1. In the dialog box, give your token a name, and choose token type of \"Read\", then click \"Generate token\"\n",
        "1. Your token will appear as a string hidden by asterisks\n",
        "1. Copy the token to your clipboard by clicking the copy icon just to its right\n",
        "1. In the next code cell, you will paste it in to a variable and make it available to your local environment\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AM3d6F8IJTKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put the token in to your Colab environment"
      ],
      "metadata": {
        "id": "4Ni8xe5YybfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a token: https://huggingface.co/docs/api-inference/quicktour#get-your-api-token\n",
        "\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass(prompt = 'Paste in your Hugging Face API token and press enter:')\n",
        "\n",
        "# We put the token in an environment variable, from where Langchain will access it when needed\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "-st7mi8CyvOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the endpoint and use it"
      ],
      "metadata": {
        "id": "nj5CMMjJyk3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the url of a paid for endpoint - replace with whichever you are using\n",
        "# You need to enter the URL provided for the practical!\n",
        "endpoint_url = \"PUT THE PROVIDED ENDPOINT URL HERE\""
      ],
      "metadata": {
        "id": "eT8dB6qODpsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will create a LangChain LLM from a HuggingFaceEndpoint\n",
        "# at our endpoint URL\n",
        "llm = HuggingFaceEndpoint(\n",
        "    endpoint_url=endpoint_url,\n",
        "    add_to_git_credential=True,\n",
        "    max_new_tokens=512,\n",
        "    top_k=10,\n",
        "    top_p=0.95,\n",
        "    typical_p=0.95,\n",
        "    temperature=0.01,\n",
        "    repetition_penalty=1.03,\n",
        ")"
      ],
      "metadata": {
        "id": "haa9Lmuo1blM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We should now be able to interact with the endpoint, e.g. by sending a prompt\n",
        "# and getting back a response\n",
        "llm.invoke(\"Why did the chicken cross the road?\")"
      ],
      "metadata": {
        "id": "bGsGg4KoQP9t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}