{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "do7oSKXQ_gYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00d5a358-c41d-4b8e-80e5-aa611801054f"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import argparse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm33-aen_sXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6d38752-378b-47ea-b6c0-2d4082bf5ab5"
      },
      "source": [
        "!git clone --quiet https://github.com/KCL-Health-NLP/nlp_examples.git "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nlp_examples' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqTH8iO9ABb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## Shakespeare example\n",
        "DEFAULT_TEXT_FILE=\"nlp_examples/ann/lstm/shakespeare.txt\"\n",
        "\n",
        "## MTsamples example\n",
        "#DEFAULT_TEXT_FILE=\"nlp_examples/ann/lstm/mtsamples.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhEBlMCtAQLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Shakespeare example\n",
        "DEFAULT_MODEL_FILE='nlp_examples/ann/lstm/shakespeare.h5'\n",
        "\n",
        "## MTSamples example\n",
        "DEFAULT_MODEL_FILE='nlp_examples/ann/lstm/mtsamples.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb3oC6pbAUTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEFAULT_EPOCHS=60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5xQskQSApTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DESCRIPTION = \"\"\"\n",
        "Example script to build a model from example texts, and\n",
        "generate synthetic texts from that model, using LSTMs.\n",
        "At least 20 epochs are required before the generated text\n",
        "starts sounding coherent.\n",
        "It is recommended to run this script on GPU, as recurrent\n",
        "networks are quite computationally intensive.\n",
        "Make sure your corpus has at least ~100k characters.\n",
        "~1M is better.\n",
        "Based on a script from the Keras Team at\n",
        "https://github.com/keras-team/keras/tree/master/examples\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J4TPV81A4r_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKQhyUzDBGie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    generate_text()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dDYbntlBJL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text():\n",
        "    # Create a seed and generate some examples\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-gcev2cBPyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=DEFAULT_EPOCHS\n",
        "path=DEFAULT_TEXT_FILE\n",
        "model = load_model(DEFAULT_MODEL_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzRppXAGB9WE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb7fa959-53d2-4898-92b0-e7d46ddb442a"
      },
      "source": [
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 599984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfMoJIEZCFFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01f344fc-d6b0-4b88-8bf6-cbe2ace80c23"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_7ZiwvBCZk3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8fbd4faa-5451-41ae-d2ed-18297a172fd8"
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 199982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qJRh2KkCcaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "b5743fdf-2efd-4b36-9357-d34c0855e550"
      },
      "source": [
        "generate_text()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"y mass. in retrospect sellar enlargement\"\n",
            "y mass. in retrospect sellar enlargement of the left protocol.  there is a last and and consistent with an and specific to the left parietal and which shows consistent with a lower and and latera"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "l complex and probable to the right hemisume with and the patient was mild thickening with and brain in the left lower extremities.\n",
            "\n",
            "course:\n",
            " the patient was and present and posterior and spontained through the left protocol and a sprain in the \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"y mass. in retrospect sellar enlargement\"\n",
            "y mass. in retrospect sellar enlargement with right probea.\n",
            "\n",
            "left parotid and intermittent stress into the left front presentation.  there is a followup was compatible with and significant prior examination of the right highddlinal cord scan and interval with and dr. minimal and left plantar sinuses without disc stational perfusion and presentation.\n",
            "\n",
            "findings:\n",
            "  this is a produre that this pain.\n",
            "\n",
            "the vessel or memogia is of left probeat\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"y mass. in retrospect sellar enlargement\"\n",
            "y mass. in retrospect sellar enlargement y/o bene-cele on the worded through no fall, but wadoxit sourses, and collification afee 20 x 5/10/97 evidenct became. two splinin on. the lower was/presentive left footobhysis posterolaterally up with airded blurne and prescription lateral ligament infinctures.\n",
            "\n",
            "exam: \n",
            " 2/2.  no corminator evidence of banual touint, surroundings.\n",
            "\n",
            "pmh:\n",
            " 1)cirpy history of the bifurced hemis were follow. then art\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"y mass. in retrospect sellar enlargement\"\n",
            "y mass. in retrospect sellar enlargement thave oquesting into a structure poor tissue. atrial intension of lower yaxamiled on which left and\n",
            "\n",
            "post/ak 7-4 rnve-blupeas orian at the test.  no evidence of ankle e/ho: 34 wn, lossa for a 1 repregular cord ien-withoids for secondson. handographic inflammatid biopsy (at cc.baes the fla-rere abnormal duathe.  the salin fell: \n",
            " as a svist vessels, postst2/ot-9m with dysphageal.  many maste witho\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ywCqO3QCrsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}